{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Some of the necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import metabolinks as mtl\n",
    "import metabolinks.transformations as transf\n",
    "#from metabolinks import read_aligned_spectra, read_spectra_from_xcel, AlignedSpectra\n",
    "from metabolinks.similarity import mz_similarity\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib import cm\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import scipy.spatial.distance as dist\n",
    "import scipy.cluster.hierarchy as hier\n",
    "import scipy.stats as stats\n",
    "import scaling as sca\n",
    "import multianalysis as ma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Read (reload) aligned from CSV - Building the datasets\n",
    "\n",
    "### All Positive Mode\n",
    "\n",
    "Two files:\n",
    "\n",
    "Norm - '5yeasts_norm_11_12.csv' - Dataset already normalized by the reference feature Leucine Enkephalin in MetaboScape (equal to the normalization function in scaling.py but having all leucine peaks at a certain intensity instead of 1 as it happens in the scaling.py module). m/z delta = 1\n",
    "\n",
    "None - '5yeasts_notnorm_2.csv' - Dataset without any kind of normalization made by MetaboScape. m/z delta = 1,1\n",
    "\n",
    "Binary analysis for each one should be identical but as they have a slightly different alignment (m/z delta parameter), they will be slightly different.\n",
    "\n",
    "#### \"None\" dataset is more relevant than Norm."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Read in the two files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def renamer(colname):\n",
    "    # Util to optionally remove all those 00000 from sample names\n",
    "    return ''.join(colname.split('00000'))\n",
    "\n",
    "leu_enk_name = '555.2692975341 Da'\n",
    "\n",
    "def reading_MetScape_file(filename,\n",
    "                          col_renamer=None,\n",
    "                          remove_ref_feat=None,\n",
    "                          prefix_to_drop=None):\n",
    "    \n",
    "    \"\"\"Read in a MetaboScape bucket table from a CSV file.\"\"\"\n",
    "    \n",
    "    data = pd.read_csv(filename).set_index('Bucket label')\n",
    "    \n",
    "    # optionally rename sample_names\n",
    "    if col_renamer is not None:\n",
    "        data = data.rename(columns=renamer)\n",
    "    \n",
    "    # optionally remove columns with a given prefix. Eg. 'ENO'\n",
    "    if prefix_to_drop is not None:\n",
    "        cols2drop = [c for c in data.columns if c.startswith(prefix_to_drop)]\n",
    "        data = data.drop(columns=cols2drop)\n",
    "    \n",
    "    # optionally remove a reference feature (if already normalized)\n",
    "    if remove_ref_feat is not None:\n",
    "        data = data.drop(index=[remove_ref_feat])\n",
    "    \n",
    "    # split in peak metadata and intensities\n",
    "    peak_cols = ['m/z', 'Name', 'Formula']\n",
    "    intensity_cols = [c for c in list(data.columns) if c not in peak_cols]\n",
    "    peaks = data[peak_cols]\n",
    "    intensities = data[intensity_cols]\n",
    "\n",
    "    # replace zeros for NaN's\n",
    "    intensities = intensities.replace(0, np.nan).dropna(how='all')\n",
    "    \n",
    "    # force peaks to have the same features as the (trimmed) intensities\n",
    "    peaks = peaks.reindex(intensities.index)\n",
    "    \n",
    "    return (peaks, intensities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks = {}\n",
    "intensities_nan = {}\n",
    "labels = 'BY4741 dGRE3 dENO1 dGLO1 dGLO2'.split() # if ENO is removed, change this\n",
    "\n",
    "# Read in the two files and keep results in dicts \n",
    "\n",
    "prefix_to_drop = leu_enk_name\n",
    "peaks_norm, yeast_norm = reading_MetScape_file('5yeasts_norm_11_12.csv', \n",
    "                                                remove_ref_feat=leu_enk_name,\n",
    "                                                col_renamer=renamer,\n",
    "                                                prefix_to_drop=prefix_to_drop)\n",
    "\n",
    "yeast_norm = mtl.add_labels(yeast_norm, labels=labels)\n",
    "\n",
    "peaks['Norm'] = peaks_norm\n",
    "intensities_nan['Norm'] = yeast_norm\n",
    "\n",
    "prefix_to_drop = None\n",
    "peaks_none, yeast_none = reading_MetScape_file('5yeasts_notnorm_2.csv', \n",
    "                                                remove_ref_feat=leu_enk_name,\n",
    "                                                col_renamer=renamer,\n",
    "                                                prefix_to_drop=prefix_to_drop)\n",
    "\n",
    "yeast_none = mtl.add_labels(yeast_none, labels=labels)\n",
    "\n",
    "peaks['None'] = peaks_none\n",
    "intensities_nan['None'] = yeast_none\n",
    "\n",
    "intensities_nan"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Removing rare features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yeast_norm_nan = intensities_nan['Norm']\n",
    "yeast_none_nan = intensities_nan['None']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing features - Lots of features that appear in only 1 sample - non-informative.\n",
    "# Function keep_atleast accepts argument min_samples\n",
    "# (integer: number of samples, [0,1[: fraction to keep)\n",
    "\n",
    "yeast_norm_nan = transf.keep_atleast(yeast_norm_nan, min_samples=2)\n",
    "yeast_none_nan = transf.keep_atleast(yeast_none_nan, min_samples=2)\n",
    "yeast_norm_nan"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Similarity analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Compute m/z similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_norm = mz_similarity(yeast_norm_nan, has_labels=True)\n",
    "sim_none = mz_similarity(yeast_none_nan, has_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Heatmaps of Jaccard similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_kws = {\"height_ratios\": (0.4, 0.4, 0.02)}\n",
    "f, ax = plt.subplots(3,2, figsize=(14, 15), gridspec_kw=grid_kws, constrained_layout=True)\n",
    "\n",
    "hm = sns.heatmap(sim_norm.sample_similarity_jaccard, annot=True, square=True, ax=ax[0][0], cmap=sns.cm.rocket_r, cbar=None)\n",
    "hm = sns.heatmap(sim_norm.label_similarity_jaccard, annot=True, square=True, ax=ax[0][1], cmap=sns.cm.rocket_r, cbar=None)\n",
    "ax[0][0].set_title('Norm data, Sample similarity')\n",
    "ax[0][1].set_title('Norm data, Group similarity')\n",
    "hm = sns.heatmap(sim_none.sample_similarity_jaccard, annot=True, square=True, \n",
    "                                                     ax=ax[1][0], cmap=sns.cm.rocket_r,\n",
    "                                                     cbar_ax=ax[2][0], cbar_kws={\"orientation\": \"horizontal\"})\n",
    "hm = sns.heatmap(sim_none.label_similarity_jaccard, annot=True, square=True, ax=ax[1][1], cmap=sns.cm.rocket_r, cbar=None)\n",
    "ax[1][0].set_title('None data, Sample similarity')\n",
    "ax[1][1].set_title('None data, Group similarity')\n",
    "ax[2][1].set_axis_off()\n",
    "#f.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Verification that `dist.pdist()` produces the same result as `mz_similarity()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_bool(df):\n",
    "    \"Transforms data into 'binary' matrices.\"\n",
    "    return df.mask(df.notnull(), 1).mask(df.isnull(), 0)\n",
    "\n",
    "yeast_norm_01 = df_to_bool(yeast_norm_nan)\n",
    "yeast_none_01 = df_to_bool(yeast_none_nan)\n",
    "\n",
    "names = list(yeast_none_01.ms.samples)\n",
    "scipy_jdist = dist.pdist(yeast_norm_01.T, metric='jaccard')\n",
    "df_scipy_dist = pd.DataFrame(dist.squareform(scipy_jdist), index=names, columns=names)\n",
    "\n",
    "\n",
    "jsim = sim_norm.sample_similarity_jaccard\n",
    "jdist = 1 - jsim\n",
    "from pandas.testing import assert_frame_equal\n",
    "assert_frame_equal(jdist, df_scipy_dist, check_dtype=False)\n",
    "# No exception should be raised!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Yeast dendogram, Jaccard distance, Norm dataset')\n",
    "jdist = dist.squareform(1 - sim_norm.label_similarity_jaccard.values)\n",
    "Z = hier.linkage(jdist, method='average')\n",
    "\n",
    "fig = plt.figure(figsize=(16,7))\n",
    "dn = hier.dendrogram(Z, labels=yeast_norm_01.ms.unique_labels,\n",
    "                     leaf_font_size=20,\n",
    "                     above_threshold_color='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hier.cophenet(Z,jdist)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Non-binary Similarity Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Set label colors for consistency in all plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# may change in the future...\n",
    "colours = cm.get_cmap('nipy_spectral', 5)(range(5))\n",
    "\n",
    "labels = list(yeast_norm_nan.ms.unique_labels)\n",
    "\n",
    "label_colors = {lbl: c for lbl, c in zip(labels, colours)}\n",
    "\n",
    "sns.palplot(label_colors.values())\n",
    "new_ticks = plt.xticks(range(len(labels)), labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Normalized MetaboScape Data (m/z delta = 1)\n",
    "\n",
    "3 types of processing:\n",
    "\n",
    "Imp_neg - MetScape Normalization, Missing Value Imputation.\n",
    "\n",
    "P_norm - MetScape Normalization, Missing Value Imputation and Pareto Scaling.\n",
    "\n",
    "NGP_norm - MetScape Normalization, Missing Value Imputation, glog transformation and Pareto Scaling.\n",
    "\n",
    "Note: Starts without Leucine Enkephalin peak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imp_norm \n",
    "Imp_norm = sca.NaN_Imputation(yeast_norm_nan, 0) #Substitute missing values with half of the minimum intensity.\n",
    "#Imp_norm.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Measure Euclidean distances\n",
    "dist_Imp_norm = dist.pdist(Imp_norm.T, metric = 'euclidean')\n",
    "\n",
    "#Constructing Dendrogram\n",
    "print('Yeast dendrogram, Euclidean distance, MetScape Normalization and NaN Imputation')\n",
    "Z_Imp_norm = hier.linkage(dist_Imp_norm, method='average') #ward, average, centroid, single, complete, weighted, median\n",
    "fig = plt.figure(figsize=(16,7))\n",
    "dn = hier.dendrogram(Z_Imp_norm, labels=Imp_norm.ms.labels,\n",
    "                     leaf_font_size=15,\n",
    "                     above_threshold_color='b')\n",
    "#Coloring labels\n",
    "ax = plt.gca()\n",
    "ax.set_ylabel('Distance (UA)')\n",
    "xlbls = ax.get_xmajorticklabels()\n",
    "for lbl in xlbls:\n",
    "    lbl.set_color(label_colors[lbl.get_text()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cophenetic Correlation Coefficient (see how the clustering - from hier.linkage - preserves the original distances)\n",
    "print(hier.cophenet(Z_Imp_norm,dist_Imp_norm)[0]) #method average seems to lead to higher coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#P_norm\n",
    "P_norm = sca.ParetoScal(Imp_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Measure Euclidean distances\n",
    "dist_P_norm = dist.pdist(P_norm.T, metric = 'euclidean')\n",
    "\n",
    "#Constructing Dendrogram\n",
    "print('Yeast dendrogram, Euclidean distance, MetScape Normalization, NaN Imputation and Pareto Scaling')\n",
    "Z_P_norm = hier.linkage(dist_P_norm, method='average') #ward, average, centroid, single, complete, weighted, median\n",
    "fig = plt.figure(figsize=(16,7))\n",
    "dn = hier.dendrogram(Z_P_norm, labels=P_norm.ms.labels,\n",
    "                     leaf_font_size=15,\n",
    "                     above_threshold_color='b')\n",
    "#Coloring labels\n",
    "ax = plt.gca()\n",
    "ax.set_ylabel('Distance (UA)')\n",
    "xlbls = ax.get_xmajorticklabels()\n",
    "for lbl in xlbls:\n",
    "    lbl.set_color(label_colors[lbl.get_text()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cophenetic Correlation Coefficient (see how the clustering - from hier.linkage - preserves the original distances)\n",
    "print(hier.cophenet(Z_P_norm,dist_P_norm)[0]) #method average seems to lead to higher coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NGP_norm\n",
    "glog_norm = sca.glog(Imp_norm)\n",
    "NGP_norm = sca.ParetoScal(glog_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Measure Euclidean distances\n",
    "dist_NGP_norm = dist.pdist(NGP_norm.T, metric = 'euclidean')\n",
    "\n",
    "#Constructing Dendrogram\n",
    "print('Yeast dendrogram, Euclidean distance, MetScape Normalization, NaN Imputation, Transformed and Pareto Scaling')\n",
    "Z_NGP_norm = hier.linkage(dist_NGP_norm, method='average') #ward, average, centroid, single, complete, weighted, median\n",
    "fig = plt.figure(figsize=(16,7))\n",
    "dn = hier.dendrogram(Z_NGP_norm, labels=NGP_norm.ms.labels,\n",
    "                     leaf_font_size=15,\n",
    "                     above_threshold_color='b')\n",
    "#Coloring labels\n",
    "ax = plt.gca()\n",
    "ax.set_ylabel('Distance (UA)')\n",
    "xlbls = ax.get_xmajorticklabels()\n",
    "for lbl in xlbls:\n",
    "    lbl.set_color(label_colors[lbl.get_text()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hier.cophenet(Z_NGP_norm,dist_NGP_norm)[0]) "
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Binary Similarity Analysis Methods - Example Dendrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_norm = df_to_bool(yeast_norm_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply one of the following: dice, hamming, jaccard, rogerstanimoto, sokalmichener, sokalsneath, yule, kulsinski, rusellrao.\n",
    "\n",
    "print('Yeast dendrogram, Binary methods, Normalized by MetScape')\n",
    "Zdice_neg = hier.linkage(aligned_norm.T, metric = 'dice', method='average')\n",
    "\n",
    "fig = plt.figure(figsize=(16,7))\n",
    "dn = hier.dendrogram(Zdice_neg, labels=yeast_norm_nan.ms.labels,\n",
    "                     leaf_font_size=15,\n",
    "                     above_threshold_color='b')\n",
    "\n",
    "#Coloring labels\n",
    "ax = plt.gca()\n",
    "ax.set_ylabel('Distance (UA)')\n",
    "xlbls = ax.get_xmajorticklabels()\n",
    "for lbl in xlbls:\n",
    "    lbl.set_color(label_colors[lbl.get_text()])"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Not-normalized MetaboScape Data\n",
    "\n",
    "4 types of processing:\n",
    "\n",
    "Imp_none - Missing Value Imputation\n",
    "\n",
    "P_none - Missing Value Imputation and Pareto Scaling.\n",
    "\n",
    "NP_none - Missing Value Imputation, Normalization by a reference feature (Leucine Enkephalin) and Pareto Scaling.\n",
    "\n",
    "NGP_none - Missing Value Imputation, Normalization by a reference feature (Leucine Enkephalin), glog transformation and Pareto Scaling.\n",
    "\n",
    "Note: Leucine Enkephalin peak was taken out when Normalization happened."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imp_none\n",
    "Imp_none = sca.NaN_Imputation(yeast_none_nan, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Measure Euclidean distances\n",
    "dist_Imp_none = dist.pdist(Imp_none.T, metric = 'euclidean')\n",
    "\n",
    "#Constructing Dendrogram\n",
    "print('Yeast dendrogram, Euclidean distance, NaN Imputation')\n",
    "Z_Imp_none = hier.linkage(dist_Imp_none, method='average') #ward, average, centroid, single, complete, weighted, median\n",
    "fig = plt.figure(figsize=(16,7))\n",
    "dn = hier.dendrogram(Z_Imp_none, labels=Imp_none.ms.labels,\n",
    "                     leaf_font_size=15,\n",
    "                     above_threshold_color='b')\n",
    "#Coloring labels\n",
    "ax = plt.gca()\n",
    "ax.set_ylabel('Distance (UA)')\n",
    "xlbls = ax.get_xmajorticklabels()\n",
    "for lbl in xlbls:\n",
    "    lbl.set_color(label_colors[lbl.get_text()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cophenetic Correlation Coefficient (see how the clustering - from hier.linkage - preserves the original distances)\n",
    "print(hier.cophenet(Z_Imp_none,dist_Imp_none)[0]) #method average seems to lead to higher coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#P_none\n",
    "P_none = sca.ParetoScal(Imp_none)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Measure Euclidean distances\n",
    "dist_P_none = dist.pdist(P_none.T, metric = 'euclidean')\n",
    "\n",
    "#Constructing Dendrogram\n",
    "print('Yeast dendrogram, Euclidean distance, NaN Imputation and Pareto Scaling')\n",
    "Z_P_none = hier.linkage(dist_P_none, method='average') #ward, average, centroid, single, complete, weighted, median\n",
    "fig = plt.figure(figsize=(16,7))\n",
    "dn = hier.dendrogram(Z_P_none, labels=P_none.ms.labels,\n",
    "                     leaf_font_size=15,\n",
    "                     above_threshold_color='b')\n",
    "#Coloring labels\n",
    "ax = plt.gca()\n",
    "ax.set_ylabel('Distance (UA)')\n",
    "xlbls = ax.get_xmajorticklabels()\n",
    "for lbl in xlbls:\n",
    "    lbl.set_color(label_colors[lbl.get_text()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cophenetic Correlation Coefficient (see how the clustering - from hier.linkage - preserves the original distances)\n",
    "print(hier.cophenet(Z_P_none,dist_P_none)[0]) #method average seems to lead to higher coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NP_none\n",
    "Norm_none = sca.Norm_Feat(Imp_none, leu_enk_name)\n",
    "NP_none = sca.ParetoScal(Norm_none)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Measure Euclidean distances\n",
    "dist_NP_none = dist.pdist(NP_none.T, metric = 'euclidean')\n",
    "\n",
    "#Constructing Dendrogram\n",
    "print('Yeast dendrogram, Euclidean distance, NaN Imputation, Normalized and Pareto Scaling')\n",
    "Z_NP_none = hier.linkage(dist_NP_none, method='average') #ward, average, centroid, single, complete, weighted, median\n",
    "fig = plt.figure(figsize=(16,7))\n",
    "dn = hier.dendrogram(Z_NP_none, labels=NP_none.ms.labels,\n",
    "                     leaf_font_size=15,\n",
    "                     above_threshold_color='b')\n",
    "#Coloring labels\n",
    "ax = plt.gca()\n",
    "ax.set_ylabel('Distance (UA)')\n",
    "xlbls = ax.get_xmajorticklabels()\n",
    "for lbl in xlbls:\n",
    "    lbl.set_color(label_colors[lbl.get_text()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hier.cophenet(Z_NP_none,dist_NP_none)[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NGP_none\n",
    "glog_none = sca.glog(Norm_none)\n",
    "NGP_none = sca.ParetoScal(glog_none)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Measure Euclidean distances\n",
    "dist_NGP_none = dist.pdist(NGP_none.T, metric = 'euclidean')\n",
    "\n",
    "#Constructing Dendrogram\n",
    "print('Yeast dendrogram, Euclidean distance, NaN Imputation, Normalized, Transformed and Pareto Scaling')\n",
    "Z_NGP_none = hier.linkage(dist_NGP_none, method='average') #ward, average, centroid, single, complete, weighted, median\n",
    "fig = plt.figure(figsize=(16,7))\n",
    "dn = hier.dendrogram(Z_NGP_none, labels=NGP_none.ms.labels,\n",
    "                     leaf_font_size=15,\n",
    "                     above_threshold_color='b')\n",
    "#Coloring labels\n",
    "ax = plt.gca()\n",
    "ax.set_ylabel('Distance (UA)')\n",
    "xlbls = ax.get_xmajorticklabels()\n",
    "for lbl in xlbls:\n",
    "    lbl.set_color(label_colors[lbl.get_text()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hier.cophenet(Z_NGP_none,dist_NGP_none)[0]) "
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Binary Similarity Analysis Methods - Example Dendrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_none = df_to_bool(yeast_none_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply one of the following: dice, hamming, jaccard, rogerstanimoto, sokalmichener, sokalsneath, yule, kulsinski, rusellrao.\n",
    "\n",
    "print('Yeast dendrogram, Binary methods, Not-Normalized by MetScape')\n",
    "Zdice_neg = hier.linkage(aligned_none.T, metric = 'dice', method ='average')\n",
    "\n",
    "fig = plt.figure(figsize=(16,7))\n",
    "dn = hier.dendrogram(Zdice_neg, labels=yeast_none_nan.ms.labels,\n",
    "                     leaf_font_size=15,\n",
    "                     above_threshold_color='b')\n",
    "\n",
    "#Coloring labels\n",
    "ax = plt.gca()\n",
    "ax.set_ylabel('Distance (UA)')\n",
    "xlbls = ax.get_xmajorticklabels()\n",
    "for lbl in xlbls:\n",
    "    lbl.set_color(label_colors[lbl.get_text()])"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Comparing Dendrograms\n",
    "\n",
    "#### Two methods: Baker's Gamma Correlation and Cophenetic Correlation Coefficient\n",
    "\n",
    "#### Examples of procedure with these methods"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Baker's method\n",
    "\n",
    "Use of the mergerank function from multianalysis to create a 'rank' of the iteration number two samples were linked to the same cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "euclidean = (Z_Imp_norm, Z_P_norm, Z_NGP_norm, Z_Imp_none, Z_P_none, Z_NP_none, Z_NGP_none)\n",
    "dist_euclidean = (dist_Imp_norm, dist_P_norm, dist_NGP_norm, dist_Imp_none, dist_P_none, dist_NP_none, dist_NGP_none)\n",
    "\n",
    "#euclidean = (Z_Imp_none, Z_P_none, Z_NP_none, Z_NGP_none)\n",
    "#dist_euclidean = (dist_Imp_none, dist_P_none, dist_NP_none, dist_NGP_none)\n",
    "\n",
    "K_BG = []\n",
    "S_BG = []\n",
    "Coph_C = []\n",
    "\n",
    "for i in range(len(euclidean)):\n",
    "    K_BG.append(ma.mergerank(euclidean[i])) #Mergerank\n",
    "    S_BG.append(K_BG[i][K_BG[i]!=0]) #Both reshape to a 1D array (needed for spearman correlation) and take out 0's \n",
    "    Coph_C.append(hier.cophenet(euclidean[i], dist_euclidean[i])) #Matrix of Cophenetic distances"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Examples\n",
    "\n",
    "According to Original Paper (Stability of Two Hierarchical Grouping Techniques Case 1: Sensitivity to Data Errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Pair of samples      \\tKendall Correlation \\tp-value')\n",
    "print('Imp_norm-P_norm   \\t', stats.kendalltau(S_BG[0],S_BG[1])[0], '\\t', stats.kendalltau(S_BG[0],S_BG[1])[1])\n",
    "print('Imp_norm-_NGP_norm\\t', stats.kendalltau(S_BG[0],S_BG[2])[0], '\\t', stats.kendalltau(S_BG[0],S_BG[2])[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "According to the explanation given in the R package dendextend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Pair of samples      \\tSpearman Correlation \\tp-value')\n",
    "print('Imp_norm-P_norm   \\t', stats.spearmanr(S_BG[0],S_BG[1])[0], '\\t', stats.spearmanr(S_BG[0],S_BG[1])[1])\n",
    "print('Imp_norm-_NGP_norm\\t', stats.spearmanr(S_BG[0],S_BG[2])[0], '\\t', stats.spearmanr(S_BG[0],S_BG[2])[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Cophenetic Correlation Coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Pair of samples      \\tPearson Correlation \\tp-value')\n",
    "print('Imp_norm-P_norm   \\t', stats.pearsonr(Coph_C[0][1],Coph_C[1][1])[0], '\\t', stats.pearsonr(Coph_C[0][1],Coph_C[1][1])[1])\n",
    "print('Imp_norm-_NGP_norm\\t', stats.pearsonr(Coph_C[0][1],Coph_C[2][1])[0], '\\t', stats.pearsonr(Coph_C[0][1],Coph_C[2][1])[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Comparison of dendrograms made with all binary metrics and euclidean distances \n",
    "\n",
    "#### Correlations between all pairs using all 3 methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#9 binary methods accepted in pdist (scipy.spatial.distances.pdist)\n",
    "binary = ('dice', 'hamming', 'jaccard', 'rogerstanimoto', 'sokalmichener', 'sokalsneath', 'yule', 'kulsinski', 'russellrao')\n",
    "#3 methods that will be used as representative of the others (others not present have similar variations to one of those 3)\n",
    "binary = ( 'jaccard', 'hamming', 'yule')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Application of all \"single\" steps needed presented in the examples above with distance metrics.\n",
    "#Normalized first by Metaboscape\n",
    "Z_norm = []\n",
    "K_norm = []\n",
    "S_norm = []\n",
    "Coph_norm = []\n",
    "\n",
    "for i in range(len(binary)):\n",
    "    Z_norm.append(hier.linkage(aligned_norm.T, metric = binary[i], method='average')) #Z\n",
    "    K_norm.append(ma.mergerank(Z_norm[i])) #Mergerank\n",
    "    S_norm.append(K_norm[i][K_norm[i]!=0]) #Eliminating 0's\n",
    "    Coph_norm.append(hier.cophenet(Z_norm[i], dist.pdist(aligned_norm.T, metric = binary[i]))) #Cophenetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Not Normalized first\n",
    "Z_none = []\n",
    "K_none = []\n",
    "S_none = []\n",
    "Coph_none = []\n",
    "\n",
    "for i in range(len(binary)):\n",
    "    Z_none.append(hier.linkage(aligned_none.T, metric = binary[i], method='average')) #Z\n",
    "    K_none.append(ma.mergerank(Z_none[i])) #Mergerank\n",
    "    S_none.append(K_none[i][K_none[i]!=0]) #Eliminating 0's\n",
    "    Coph_none.append(hier.cophenet(Z_none[i], dist.pdist(aligned_none.T, metric = binary[i]))) #Cophenetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creation of a list with all the \"rank\" values (in order) for the different metrics: \n",
    "#Norm Conventional, None Conventional, Norm Binaries, None Binaries\n",
    "S = []\n",
    "S.extend(S_BG)\n",
    "S.extend(S_norm)#\n",
    "S.extend(S_none)\n",
    "#Creation of a list with all the returns from the function cophenetic for the different metrics: \n",
    "#Norm Conventional, None Conventional, Norm Binaries, None Binaries\n",
    "Coph = []\n",
    "Coph.extend(Coph_C)\n",
    "Coph.extend(Coph_norm)#\n",
    "Coph.extend(Coph_none)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Creation of all dataframes needed to store all correlation coeficients and respective p-values fot all three methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Column names and row names for the dataframes\n",
    "colnames = ['Imp_norm', 'P_norm', 'NGP_norm', 'Imp_none', 'P_none', 'NP_none', 'NGP_none', 'jaccard_norm', 'hamming_norm',\n",
    "            'yule_norm', 'jaccard_none', 'hamming_none', 'yule_none']\n",
    "#colnames = ['Imp_none', 'P_none', 'NP_none', 'NGP_none', 'jaccard_none', 'hamming_none', 'yule_none']            \n",
    "            #'dice_norm', 'hamming_norm',\n",
    "            #'jaccard_norm', 'rogerstanimoto_norm', 'sokalmichener_norm', 'sokalsneath_norm','yule_norm', 'kulsinski_norm', \n",
    "            #'russellrao_norm','dice_none', 'hamming_none', 'jaccard_none', 'rogerstanimoto_none', \n",
    "            #'sokalmichener_none', 'sokalsneath_none', 'yule_none', 'kulsinski_none', 'russellrao_none']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_K = pd.DataFrame(np.zeros((len(S),len(S))), columns = colnames, index = colnames) #K - Kendall (Baker)\n",
    "df_S = pd.DataFrame(np.zeros((len(S),len(S))), columns = colnames, index = colnames) #S - Spearman (Baker)\n",
    "df_C = pd.DataFrame(np.zeros((len(S),len(S))), columns = colnames, index = colnames) #C - Cophenetic Correlation\n",
    "df_K_p = pd.DataFrame(np.zeros((len(S),len(S))), columns = colnames, index = colnames) #p-values of K method\n",
    "df_S_p = pd.DataFrame(np.zeros((len(S),len(S))), columns = colnames, index = colnames) #p-values of S method\n",
    "df_C_p = pd.DataFrame(np.zeros((len(S),len(S))), columns = colnames, index = colnames) #p-values of C method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculation of correlation coefficient for each method\n",
    "for i in range(len(S)):\n",
    "    for j in range(len(S)):\n",
    "        df_K.iloc[i,j] = stats.kendalltau(S[i],S[j])[0] #Correlation coefficient\n",
    "        df_S.iloc[i,j] = stats.spearmanr(S[i],S[j])[0] #Correlation coefficient\n",
    "        df_C.iloc[i,j] = stats.pearsonr(Coph[i][1],Coph[j][1])[0] #Correlation coefficient\n",
    "        df_K_p.iloc[i,j] = stats.kendalltau(S[i],S[j])[1] #p-value\n",
    "        df_S_p.iloc[i,j] = stats.spearmanr(S[i],S[j])[1] #p-value\n",
    "        df_C_p.iloc[i,j] = stats.pearsonr(Coph[i][1],Coph[j][1])[1] #p-value\n",
    "\n",
    "#Inserting blank lines in the DataFrame for better presentation and separation\n",
    "line = pd.DataFrame(np.empty((1,len(S)))* np.nan, columns = colnames, index=[''])\n",
    "lineV = pd.concat([line.iloc[:,:7], pd.DataFrame(np.empty((1,1))* np.nan, columns =[''], index = ['']), line.iloc[:,7:]], axis = 1)\n",
    "df_KI = pd.concat([df_K.iloc[:7], line, df_K.iloc[7:]])\n",
    "df_KI = pd.concat([df_KI.iloc[:,:7], lineV.T, df_KI.iloc[:,7:]], axis = 1)\n",
    "df_SI = pd.concat([df_S.iloc[:7], line, df_S.iloc[7:]])\n",
    "df_SI = pd.concat([df_SI.iloc[:,:7], lineV.T, df_SI.iloc[:,7:]], axis = 1)\n",
    "df_CI = pd.concat([df_C.iloc[:7], line, df_C.iloc[7:]])\n",
    "df_CI = pd.concat([df_CI.iloc[:,:7], lineV.T, df_CI.iloc[:,7:]], axis = 1)\n",
    "#line = pd.DataFrame(np.empty((1,10))* np.nan, columns = ['Imp_none', 'P_none', 'NP_none', 'NGP_none', 'jaccard_norm', 'hamming_norm',\n",
    "            #'yule_norm', 'jaccard_none', 'hamming_none', 'yule_none'], index=[''])\n",
    "#lineV = pd.concat([line.iloc[:,:4], pd.DataFrame(np.empty((1,1))* np.nan, columns =[''], index = ['']), line.iloc[:,4:]], axis = 1)\n",
    "#df_CI = pd.concat([df_C.iloc[3:7, 3:], line, df_C.iloc[10:,3:]])\n",
    "#df_CI = pd.concat([df_CI.iloc[:,:4], lineV.T, df_CI.iloc[:,4:]], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Heatmaps of the correlation coeficients for the 3 methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "print('Baker (Kendall) Correlation Coefficient Heatmap (between dendrograms made with different distance metrics)')\n",
    "print('Name Convention: Treatment/Binary metric_data type')\n",
    "print('Norm - MetaboScape normalized data')\n",
    "print('None - MetaboScape not normalized data')\n",
    "hm = sns.heatmap(df_KI, annot=True, ax=ax, cmap = sns.cm.rocket_r)\n",
    "bottom, top = ax.get_ylim()\n",
    "ax.set_ylim(bottom + 0.5, top - 0.5)\n",
    "plt.text(3.5,-0.2,'Conventional', fontsize  = 15, horizontalalignment='center')\n",
    "plt.text(14.2,3.5,'Conventional', fontsize  = 15, rotation = 270, verticalalignment='center')\n",
    "plt.text(11,-0.2,'Binaries', fontsize = 15, horizontalalignment='center')\n",
    "plt.text(14.1,11,'Binaries', fontsize  = 15, rotation = 270, verticalalignment='center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "print('Baker (Spearman) Correlation Coefficient Heatmap (between dendrograms made with different distance metrics)')\n",
    "print('Name Convention: Treatment/Binary metric_data type')\n",
    "print('Norm - MetaboScape normalized data')\n",
    "print('None - MetaboScape not normalized data')\n",
    "hm = sns.heatmap(df_SI, annot=True, ax=ax, cmap = sns.cm.rocket_r)\n",
    "bottom, top = ax.get_ylim()\n",
    "ax.set_ylim(bottom + 0.5, top - 0.5)\n",
    "plt.text(3.5,-0.2,'Conventional', fontsize  = 15, horizontalalignment='center')\n",
    "plt.text(14.2,3.5,'Conventional', fontsize  = 15, rotation = 270, verticalalignment='center')\n",
    "plt.text(11,-0.2,'Binaries', fontsize = 15, horizontalalignment='center')\n",
    "plt.text(14.1,11,'Binaries', fontsize  = 15, rotation = 270, verticalalignment='center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "print('Cophenetic Correlation Coefficient Heatmap (between dendrograms made with different distance metrics)')\n",
    "print('Name Convention: Treatment/Binary metric_data type')\n",
    "print('Norm - MetaboScape normalized data')\n",
    "print('None - MetaboScape not normalized data')\n",
    "hm = sns.heatmap(df_CI, annot=True, ax=ax, cmap = sns.cm.rocket_r)\n",
    "bottom, top = ax.get_ylim()\n",
    "ax.set_ylim(bottom + 0.5, top - 0.5)\n",
    "plt.text(3.5,-0.2,'Conventional', fontsize  = 15, horizontalalignment='center')\n",
    "plt.text(14.2,3.5,'Conventional', fontsize  = 15, rotation = 270, verticalalignment='center')\n",
    "plt.text(11,-0.2,'Binaries', fontsize = 15, horizontalalignment='center')\n",
    "plt.text(14.1,11,'Binaries', fontsize  = 15, rotation = 270, verticalalignment='center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Hierarchical clustering of the correlation coeficients of dendrograms made with different distance metrics with each other"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Colours for these labels (groups: Norm Conventional, None Conventional, Norm Binary, None Binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_colors2 = {}\n",
    "colours2 = cm.get_cmap('nipy_spectral', 4)\n",
    "col_lbl2 = colours2(range(4))\n",
    "for i in range(2):\n",
    "    label_colors2[df_K.columns[3*i]] = col_lbl2[i]\n",
    "    label_colors2[df_K.columns[3*i+1]] = col_lbl2[i]\n",
    "    label_colors2[df_K.columns[3*i+2]] = col_lbl2[i]\n",
    "    label_colors2[df_K.columns[3*i+3]] = col_lbl2[i]\n",
    "for i in range(3):\n",
    "    label_colors2[df_K.columns[7+i]] = col_lbl2[2]\n",
    "    label_colors2[df_K.columns[10+i]] = col_lbl2[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Baker (Kendall) Correlation Coefficient Heatmap (between dendrograms made with different distance metrics)')\n",
    "print('Name Convention: Treatment/Binary metric_data type')\n",
    "print('Norm - MetaboScape normalized data')\n",
    "print('None - MetaboScape not normalized data')\n",
    "Z_K = hier.linkage(df_K, metric = 'euclidean', method = 'average')\n",
    "fig = plt.figure(figsize=(16,7))\n",
    "dn = hier.dendrogram(Z_K, labels=df_K.columns,\n",
    "                     leaf_font_size=15,\n",
    "                     above_threshold_color='b',\n",
    "                     orientation = 'left')\n",
    "#Coloring labels\n",
    "ax = plt.gca()\n",
    "ax.set_xlabel('Distance (UA)')\n",
    "xlbls = ax.get_ymajorticklabels()\n",
    "for lbl in xlbls:\n",
    "    lbl.set_color(label_colors2[lbl.get_text()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Baker (Spearman) Correlation Coefficient Heatmap (between dendrograms made with different distance metrics)')\n",
    "print('Name Convention: Treatment/Binary metric_data type')\n",
    "print('Norm - MetaboScape normalized data')\n",
    "print('None - MetaboScape not normalized data')\n",
    "Z_S = hier.linkage(df_S, metric = 'euclidean', method = 'average')\n",
    "fig = plt.figure(figsize=(16,7))\n",
    "dn = hier.dendrogram(Z_S, labels=df_S.columns,\n",
    "                     leaf_font_size=15,\n",
    "                     above_threshold_color='b',\n",
    "                     orientation = 'left')\n",
    "#Coloring labels\n",
    "ax = plt.gca()\n",
    "ax.set_xlabel('Distance (UA)')\n",
    "xlbls = ax.get_ymajorticklabels()\n",
    "for lbl in xlbls:\n",
    "    lbl.set_color(label_colors2[lbl.get_text()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Cophenetic Correlation Coefficient Heatmap (between dendrograms made with different distance metrics)')\n",
    "print('Name Convention: Treatment/Binary metric_data type')\n",
    "print('Norm - MetaboScape normalized data')\n",
    "print('None - MetaboScape not normalized data')\n",
    "Z_C = hier.linkage(df_C, metric = 'euclidean', method = 'average')\n",
    "fig = plt.figure(figsize=(16,7))\n",
    "dn = hier.dendrogram(Z_C, labels=df_C.columns,\n",
    "                     leaf_font_size=15,\n",
    "                     above_threshold_color='b',\n",
    "                     orientation = 'left')\n",
    "#Coloring labels\n",
    "ax = plt.gca()\n",
    "ax.set_xlabel('Distance (UA)')\n",
    "xlbls = ax.get_ymajorticklabels()\n",
    "for lbl in xlbls:\n",
    "    lbl.set_color(label_colors2[lbl.get_text()])"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Distance discrimination of all methods applied (and shown in previous heatmap/dendrogram)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing Z linkage matrices\n",
    "Z = []\n",
    "Z.extend(euclidean)\n",
    "Z.extend(Z_norm)\n",
    "Z.extend(Z_none)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_average = np.zeros((1,13))\n",
    "disc_median = np.zeros((1,13))\n",
    "disc_correct = np.zeros((1,13))\n",
    "for i in range(len(Z)):\n",
    "    discrim = sca.dist_discrim(yeast_norm_nan, Z[i], method = 'average')  #all samples have the same order\n",
    "    disc_average[0,i] = discrim[0]\n",
    "    disc_median[0,i] = sca.dist_discrim(yeast_norm_nan, Z[i], 'median')[0] #all samples have the same order\n",
    "    correct = np.array(list(discrim[1].values()))\n",
    "    disc_correct[0,i] = len(correct[correct>0])\n",
    "\n",
    "disc_average = pd.DataFrame(disc_average, index = ['distances average'], columns = colnames)\n",
    "disc_median = pd.DataFrame(disc_median, index = ['distances median'], columns = colnames)\n",
    "disc_correct = pd.DataFrame(disc_correct, index = ['correct groupings'], columns = colnames)\n",
    "\n",
    "#Inserting blank lines in the DataFrame for better presentation and separation\n",
    "line = pd.DataFrame(np.empty((1,1))* np.nan, index = [''])\n",
    "disc_average = pd.concat([disc_average.iloc[:,:7], pd.DataFrame(np.empty((1,1))* np.nan, index = [''],\n",
    "                                                columns = ['distances average']).T, disc_average.iloc[:,7:]], axis = 1)\n",
    "disc_median = pd.concat([disc_median.iloc[:,:7], pd.DataFrame(np.empty((1,1))* np.nan, index = [''],\n",
    "                                                columns = ['distances median']).T, disc_median.iloc[:,7:]], axis = 1)\n",
    "disc_correct = pd.concat([disc_correct.iloc[:,:7], pd.DataFrame(np.empty((1,1))* np.nan, index = [''],\n",
    "                                                columns = ['correct groupings']).T, disc_correct.iloc[:,7:]], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(20, 1))\n",
    "hm = sns.heatmap(disc_average, annot=True, ax=ax, cmap = sns.cm.rocket_r)\n",
    "plt.text(2.85,-0.2,'Conventional', fontsize  = 12)\n",
    "plt.text(10.6,-0.2,'Binaries', fontsize = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(20, 1))\n",
    "hm = sns.heatmap(disc_median, annot=True, ax=ax, cmap = sns.cm.rocket_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(20, 1))\n",
    "hm = sns.heatmap(disc_correct, annot=True, ax=ax, cmap = sns.cm.rocket_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_average = np.zeros((1,13))\n",
    "disc_median = np.zeros((1,13))\n",
    "disc_correct = np.zeros((1,13))\n",
    "for i in range(len(Z)):\n",
    "    discrim = sca.dist_discrim(yeast_norm_nan, Z[i], 3, method = 'average')  #all samples have the same order\n",
    "    disc_average[0,i] = discrim[0]\n",
    "    disc_median[0,i] = sca.dist_discrim(yeast_norm_nan, Z[i], 3, 'median')[0] #all samples have the same order\n",
    "    correct = np.array(list(discrim[1].values()))\n",
    "    disc_correct[0,i] = len(correct[correct>0])\n",
    "\n",
    "disc_average = pd.DataFrame(disc_average, index = ['distances average'], columns = colnames)\n",
    "disc_median = pd.DataFrame(disc_median, index = ['distances median'], columns = colnames)\n",
    "disc_correct = pd.DataFrame(disc_correct, index = ['correct groupings'], columns = colnames)\n",
    "\n",
    "#Inserting blank lines in the DataFrame for better presentation and separation\n",
    "line = pd.DataFrame(np.empty((1,1))* np.nan, index = [''])\n",
    "disc_average = pd.concat([disc_average.iloc[:,3:7], pd.DataFrame(np.empty((1,1))* np.nan, index = [''],\n",
    "                                                columns = ['distances average']).T, disc_average.iloc[:,10:]], axis = 1)\n",
    "disc_median = pd.concat([disc_median.iloc[:,3:7], pd.DataFrame(np.empty((1,1))* np.nan, index = [''],\n",
    "                                                columns = ['distances median']).T, disc_median.iloc[:,10:]], axis = 1)\n",
    "disc_correct = pd.concat([disc_correct.iloc[:,3:7], pd.DataFrame(np.empty((1,1))* np.nan, index = [''],\n",
    "                                                columns = ['correct groupings']).T, disc_correct.iloc[:,10:]], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(8, 1))\n",
    "hm = sns.heatmap(disc_average, annot=True, ax=ax, cmap = sns.cm.rocket_r)\n",
    "plt.text(2,-0.2,'Conventional', fontsize  = 12, horizontalalignment='center')\n",
    "plt.text(6.5,-0.2,'Binaries', fontsize  = 12, horizontalalignment='center')"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(8, 1))\n",
    "hm = sns.heatmap(disc_median, annot=True, ax=ax, cmap = sns.cm.rocket_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(8, 1))\n",
    "hm = sns.heatmap(disc_correct, annot=True, ax=ax, cmap = sns.cm.rocket_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### K-means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.cluster as skclust"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Example of what happens in a K-means clustering and how samples are separated \n",
    "Use of the module do sci-kit learn - sklearn. Cluster number equal to the amount of varieties. How well can this method separate the varieties. Default parameters except number of clusters.\n",
    "\n",
    "This example doesn't necessarily mirror the results below (for the case in example) since K-means clustering has an intrinsically random side to it and the clustering is performed again for the case example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Kmean = skclust.KMeans(n_clusters=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Kmean.fit(NGP_none.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicto = {}\n",
    "for i in range(len(a.labels_)):\n",
    "    if a.labels_[i] in dicto:\n",
    "        dicto[a.labels_[i]].append(yeast_norm_nan.ms.labels[i])\n",
    "    else:\n",
    "        dicto[a.labels_[i]] = [yeast_norm_nan.ms.labels[i]]\n",
    "dicto"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### K-means clustering applied to all euclidean methods and the binary matrixes built\n",
    "\n",
    "To try and get a condensed and more easily digestible version of the results, a method similar to the discrimination distance performed in the hierarchical clustering was made. The same metrics as before are used.\n",
    "\n",
    "Replicates of a variety can be together in a cluster but, if there are more samples in the same cluster, its \"discrimination distance\" is still zero. Therefore, this method is harsher than the original dist_discrim method. The distance is calculated as the distance between the centroid of the cluster where the samples are and the closest centroid. This distance is normalized by dividing it by the maximum distance between any 2 centroids of the clusters formed. The mean/median of the discrimination distances of all groups is then a measure of the global discrimination distance\n",
    "\n",
    "Use of the Kmeans_discrim function from multianalysis to calculate discrimination distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames2 = ['Imp_norm', 'P_norm', 'NGP_norm', 'Imp_none', 'P_none', 'NP_none','NGP_none', 'binary_norm','binary_none']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "euclidean = (Imp_norm, P_norm, NGP_norm, Imp_none, P_none, NP_none, NGP_none)\n",
    "binaries = (aligned_norm, aligned_none)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_average = np.zeros((1,9))\n",
    "disc_median = np.zeros((1,9))\n",
    "disc_correct = np.zeros((1,9))\n",
    "for i in range(len(euclidean)):\n",
    "    discrim = ma.Kmeans_discrim(euclidean[i], method = 'average')  #all samples have the same order\n",
    "    disc_average[0,i] = discrim[0]\n",
    "    disc_median[0,i] = ma.Kmeans_discrim(euclidean[i], method = 'median')[0] #all samples have the same order\n",
    "    correct = np.array(list(discrim[1].values()))\n",
    "    disc_correct[0,i] = len(correct[correct>0])\n",
    "for i in range(len(binaries)):\n",
    "    discrim = ma.Kmeans_discrim(binaries[i], method = 'average')\n",
    "    disc_average[0,7 + i] \n",
    "    disc_average[0,7 + i] = discrim[0]\n",
    "    disc_median[0,7 + i] = ma.Kmeans_discrim(binaries[i], method = 'median')[0] \n",
    "    correct = np.array(list(discrim[1].values()))\n",
    "    disc_correct[0,7 + i] = len(correct[correct>0])\n",
    "\n",
    "disc_average = pd.DataFrame(disc_average, index = ['distances average'], columns = colnames2)\n",
    "disc_median = pd.DataFrame(disc_median, index = ['distances median'], columns = colnames2)\n",
    "disc_correct = pd.DataFrame(disc_correct, index = ['correct groupings'], columns = colnames2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(13.5, 1))\n",
    "hm = sns.heatmap(disc_average, annot=True, ax=ax, cmap = sns.cm.rocket_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(13.5, 1))\n",
    "hm = sns.heatmap(disc_median, annot=True, ax=ax, cmap = sns.cm.rocket_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(13.5, 1))\n",
    "hm = sns.heatmap(disc_correct, annot=True, ax=ax, cmap = sns.cm.rocket_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### RandomForests Attempts - 3-fold cross-validation, n_estimators = 200\n",
    "\n",
    "This section of the notebook takes some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creation of \"binary\" Spectras using the binary matrices built with the function df_to_bool.\n",
    "binary_norm = aligned_norm.copy()\n",
    "binary_none = aligned_none.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "euclidean = (Imp_norm, P_norm, NGP_norm, binary_norm, Imp_none, P_none, NP_none, NGP_none)\n",
    "binaries = (aligned_norm, aligned_none)\n",
    "colnames2 = ['Imp_norm', 'P_norm', 'NGP_norm', 'binary_norm','Imp_none', 'P_none', 'NP_none','NGP_none','binary_none']"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Test number of trees needed for convergence for N, NP, NGP and binary data (both alignments)\n",
    "\n",
    "Grid search of number of trees from 10 to 1000 for the random forests. See where the cross-validation score stops improving for each one.\n",
    "\n",
    "#### Takes  considerable time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vector with values for the parameter n_estimators\n",
    "values = {}\n",
    "values['n_estimators'] = range(10,150,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import sklearn.ensemble as skensemble\n",
    "rf = skensemble.RandomForestClassifier(n_estimators = 200)\n",
    "clf = GridSearchCV(rf, values, cv =3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = []\n",
    "test_score = []\n",
    "for i in range(len(euclidean)):\n",
    "    clf.fit(euclidean[i].T, euclidean[i].ms.labels)\n",
    "    param.append(clf.cv_results_['param_n_estimators'])\n",
    "    test_score.append(clf.cv_results_['mean_test_score'])\n",
    "for i in range(len(binaries)):\n",
    "    clf.fit(binaries[i].T, yeast_norm_nan.ms.labels)\n",
    "    param.append(clf.cv_results_['param_n_estimators'])\n",
    "    test_score.append(clf.cv_results_['mean_test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12,9))\n",
    "for i in range(len(param)):\n",
    "    plt.plot(param[i], test_score[i])\n",
    "plt.ylabel('3-fold-CV Mean Test Score', fontsize = 15)\n",
    "plt.xlabel('Number of Trees', fontsize = 15)\n",
    "plt.ylim([0.5,1.01])\n",
    "ax.legend(['Imp','P', 'NP','NGP','Binary'])\n",
    "ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "print('Performance based on number of trees - Alignment: None, Positive Mode')"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Applications of different methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparations of dicts:\n",
    "Scores = {}\n",
    "Scores_std = {}\n",
    "Imp_feat = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Attempt/Method n1 - Direct\n",
    "\n",
    "### Simple application of random forests\n",
    "\n",
    "Since the dataset is small, the random forest classification is iterated 20 times to make sure more combinations of training and test samples are used. Then, an average of the results are obtained - number of random forests can be decided by iter_num. This is the same for all methods. \n",
    "\n",
    "To offset the small dataset, 3-fold Cross-Validation is used as an internal validation system evaluating the performance of the model based on its score/accuracy (3-fold since that is maximum number possible since every group of samples only has 3 replicates.\n",
    "\n",
    "Besides the 3-fold cross-validation score, the order of the average of most important features across the random forests (with each iteration and group in cross-validation having the same weight) is extracted from the forests \"built\"."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Now to run the random forests on the different datasets (negative and positive of both alignments) both in their \"normal\" and \"binary\" matrices form. For the normal or euclidean matrices, only the data concerning the P data processing was used since it was the best performer of all former methods employed.\n",
    "\n",
    "Application of the function simple_RF from multianalysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#euclidean = (Imp_norm, P_norm, NGP_norm, Imp_none, P_none, NP_none, NGP_none, binary_norm, binary_none)\n",
    "I1_D = ma.simple_RF(Imp_norm)#, iter_num = 100)#(Scores, Cohen's Kappa Score, order of features based on importances, 3-fold cross-validation)\n",
    "Scores['Imp_norm'] = I1_D[0]\n",
    "Scores_std['Imp_norm'] = np.std(I1_D[0])\n",
    "Imp_feat['Imp_norm'] = I1_D[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P1_D = ma.simple_RF(P_norm)#, iter_num = 100)\n",
    "Scores['P_norm'] = P1_D[0]\n",
    "Scores_std['P_norm'] = np.std(P1_D[0])\n",
    "Imp_feat['P_norm'] = P1_D[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NGP1_D = ma.simple_RF(NGP_norm)#, iter_num = 100)\n",
    "Scores['NGP_norm'] = NGP1_D[0]\n",
    "Scores_std['NGP_norm'] = np.std(NGP1_D[0])\n",
    "Imp_feat['NGP_norm'] = NGP1_D[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I2_D = ma.simple_RF(Imp_none)#, iter_num = 100)\n",
    "Scores['Imp_none'] = I2_D[0]\n",
    "Scores_std['Imp_none'] = np.std(I2_D[0])\n",
    "Imp_feat['Imp_none'] = I2_D[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P2_D = ma.simple_RF(P_none)#, iter_num = 100)\n",
    "Scores['P_none'] = P2_D[0]\n",
    "Scores_std['P_none'] = np.std(P2_D[0])\n",
    "Imp_feat['P_none'] = P2_D[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NP2_D = ma.simple_RF(NP_none)#, iter_num = 100)\n",
    "Scores['NP_none'] = NP2_D[0]\n",
    "Scores_std['NP_none'] = np.std(NP2_D[0])\n",
    "Imp_feat['NP_none'] = NP2_D[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NGP2_D = ma.simple_RF(NGP_none)#, iter_num = 100)\n",
    "Scores['NGP_none'] = NGP2_D[0]\n",
    "Scores_std['NGP_none'] = np.std(NGP2_D[0])\n",
    "Imp_feat['NGP_none'] = NGP2_D[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B1_D = ma.simple_RF(binary_norm)#, iter_num = 100)\n",
    "Scores['binary_norm'] = B1_D[0]\n",
    "Scores_std['binary_norm'] = np.std(B1_D[0])\n",
    "Imp_feat['binary_norm'] = B1_D[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B2_D = ma.simple_RF(binary_none)#, iter_num = 100)\n",
    "Scores['binary_none'] = B2_D[0]\n",
    "Scores_std['binary_none'] = np.std(B2_D[0])\n",
    "Imp_feat['binary_none'] = B2_D[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Attempt/Method n2 - SMOTE -  NOT APPLIED SO FAR - Code in Markdown\n",
    "\n",
    "### Oversampling data with SMOTE before splitting cross-validation groups. Expected better results due to bleed.\n",
    "\n",
    "All the same specifications as method n1 but with an oversampling of the data that doubles the amount of samples (from 39 to 78) which means each cross-valdiation group will have 2 replicates for each variety instead of one.\n",
    "\n",
    "As mentioned in the title, this means there will be a \"bleeding\" of the data between test and training groups due to the samples in the test group having been originated from the ones in the training group or have been used to originate data in training groups. Therefore, the score of this method should be higher than the other due to an overestimation of how good the model is due to this bleeding."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMOTE oversampling is performed in the initial imputated data by the function fast_SMOTE from multianalysis.py. \n",
    "\n",
    "Therefore we have to run the NGP data processing again for each dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neg1\n",
    "Imp_S_neg = ma.fast_SMOTE(Imputated_neg)\n",
    "Norm_S_neg = sca.Norm_Feat(Imp_S_neg, 554.26202)\n",
    "glog_S_neg = sca.glog(Norm_S_neg)\n",
    "Euc_NGP_S_neg = sca.ParetoScal(glog_S_neg)\n",
    "#Neg2\n",
    "Imp_S_neg2 = ma.fast_SMOTE(Imputated_neg2)\n",
    "Norm_S_neg2 = sca.Norm_Feat(Imp_S_neg2, 554.26202)\n",
    "glog_S_neg2 = sca.glog(Norm_S_neg2)\n",
    "Euc_NGP_S_neg2 = sca.ParetoScal(glog_S_neg2)\n",
    "#Pos1\n",
    "Imp_S_pos = ma.fast_SMOTE(Imputated_pos)\n",
    "Norm_S_pos = sca.Norm_Feat(Imp_S_pos, 556.2765712820513)\n",
    "glog_S_pos = sca.glog(Norm_S_pos)\n",
    "Euc_NGP_S_pos = sca.ParetoScal(glog_S_pos)\n",
    "#Pos2\n",
    "Imp_S_pos2 = ma.fast_SMOTE(Imputated_pos2)\n",
    "Norm_S_pos2 = sca.Norm_Feat(Imp_S_pos2, 556.2765712820513)\n",
    "glog_S_pos2 = sca.glog(Norm_S_pos2)\n",
    "Euc_NGP_S_pos2 = sca.ParetoScal(glog_S_pos2)\n",
    "#Binaries\n",
    "binary_S_neg1 = ma.fast_SMOTE(binary_neg1, binary = True)\n",
    "binary_S_neg2 = ma.fast_SMOTE(binary_neg2, binary = True)\n",
    "binary_S_pos1 = ma.fast_SMOTE(binary_pos1, binary = True)\n",
    "binary_S_pos2 = ma.fast_SMOTE(binary_pos2, binary = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N1_B = ma.simple_RF(Euc_NGP_S_neg)\n",
    "Scores['neg2-1_bleed'] = N1_B[0]\n",
    "CKS['neg2-1_bleed'] = N1_B[1]\n",
    "Imp_feat['neg2-1_bleed'] = N1_B[2]\n",
    "Cross_Val['neg2-1_bleed'] = N1_B[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P1_B = ma.simple_RF(Euc_NGP_S_pos)\n",
    "Scores['pos2-1_bleed'] = P1_B[0]\n",
    "CKS['pos2-1_bleed'] = P1_B[1]\n",
    "Imp_feat['pos2-1_bleed'] = P1_B[2]\n",
    "Cross_Val['pos2-1_bleed'] = P1_B[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N2_B = ma.simple_RF(Euc_NGP_S_neg2)\n",
    "Scores['neg3-3_bleed'] = N2_B[0]\n",
    "CKS['neg3-3_bleed'] = N2_B[1]\n",
    "Imp_feat['neg3-3_bleed'] = N2_B[2]\n",
    "Cross_Val['neg3-3_bleed'] = N2_B[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P2_B = ma.simple_RF(Euc_NGP_S_pos2)\n",
    "Scores['pos3-3_bleed'] = P2_B[0]\n",
    "CKS['pos3-3_bleed'] = P2_B[1]\n",
    "Imp_feat['pos3-3_bleed'] = P2_B[2]\n",
    "Cross_Val['pos3-3_bleed'] = P2_B[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BN1_B = ma.simple_RF(binary_S_neg1)\n",
    "Scores['neg2-1_bin_bleed'] = BN1_B[0]\n",
    "CKS['neg2-1_bin_bleed'] = BN1_B[1]\n",
    "Imp_feat['neg2-1_bin_bleed'] = BN1_B[2]\n",
    "Cross_Val['neg2-1_bin_bleed'] = BN1_B[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BP1_B = ma.simple_RF(binary_S_pos1)\n",
    "Scores['pos2-1_bin_bleed'] = BP1_B[0]\n",
    "CKS['pos2-1_bin_bleed'] = BP1_B[1]\n",
    "Imp_feat['pos2-1_bin_bleed'] = BP1_B[2]\n",
    "Cross_Val['pos2-1_bin_bleed'] = BP1_B[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BN2_B = ma.simple_RF(binary_S_neg2)\n",
    "Scores['neg3-3_bin_bleed'] = BN2_B[0]\n",
    "CKS['neg3-3_bin_bleed'] = BN2_B[1]\n",
    "Imp_feat['neg3-3_bin_bleed'] = BN2_B[2]\n",
    "Cross_Val['neg3-3_bin_bleed'] = BN2_B[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BP2_B = ma.simple_RF(binary_S_pos2)\n",
    "Scores['pos3-3_bin_bleed'] = BP2_B[0]\n",
    "CKS['pos3-3_bin_bleed'] = BP2_B[1]\n",
    "Imp_feat['pos3-3_bin_bleed'] = BP2_B[2]\n",
    "Cross_Val['pos3-3_bin_bleed'] = BP2_B[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Results of the Random Forests surmised in Heatmaps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(15,6))\n",
    "colors = ['purple','blue','green','red','purple','blue','orange','green','red']\n",
    "data = pd.DataFrame.from_dict(Scores)\n",
    "sns.violinplot( data = data, palette = colors*2, alpha = 0.5)\n",
    "plt.ylabel('Prediction Accuracy - Random Forest', fontsize = 15)\n",
    "ax.tick_params(axis='both', which='major', labelsize = 12)\n",
    "print('Accuracy based on the dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Scores_A = {}\n",
    "for i in Scores:\n",
    "    Scores_A[i] = np.mean(Scores[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Scores_H = pd.DataFrame(list(Scores_A.values()), index = Scores_A.keys()).T\n",
    "Scores_std_H = pd.DataFrame(list(Scores_std.values()), index = Scores_std.keys()).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(13.5, 1))\n",
    "hm = sns.heatmap(Scores_H, annot=True, ax=ax, cmap = sns.cm.rocket_r, yticklabels = ['RF_CV_Scores'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(13.5, 1))\n",
    "hm = sns.heatmap(Scores_std_H, annot=True, ax=ax, cmap = sns.cm.rocket_r, yticklabels = ['RF_CV_std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Scores_H = pd.DataFrame(list(Scores_A.values()), index = Scores_A.keys(), columns = ['Accuracy']).T\n",
    "Scores_std_H = pd.DataFrame(list(Scores_std.values()), index = Scores_A.keys()).T\n",
    "Scores_ic = Scores_std_H / (100**0.5)*1.96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.set_context('notebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(20, 9))\n",
    "#sns.set_context('talk')\n",
    "color = ['purple','blue','orange','green','red']\n",
    "plt.bar(height = Scores_H.T['Accuracy'], x = Scores_H.columns, width = 0.5, color = color, alpha = 0.6)\n",
    "ax.errorbar(x = Scores_H.columns, y = Scores_H.T['Accuracy'], yerr = Scores_std_H.iloc[0,:], \n",
    "            ls = 'none', ecolor = 'black', capsize = 6)\n",
    "plt.ylim(0,1.05)\n",
    "ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "plt.ylabel('Random Forest Prediction Accuracy', fontsize = 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Characteristics of the features seen as important in the different alignments, data treatments and modes (negative and positive)\n",
    "\n",
    "We take the 2% most important features in each case and calculate the average number of samples those features appear (samples_m), the average number of different groups/varieties those features appear in (groups_n) and the ratio between these two measures (ratio_m, has a maximum of 3). We also see how many times the importance of the most importante feature is greater than the average importance of a feature in each case ('magni') as well as the % of the model explained (that use) the 2% of the most important features ('more').\n",
    "\n",
    "A scatter plot is also built to see the distributions of the number of samples each important feature in each method appears to see their overall distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the number of samples, groups, ratios for each important feature, magnitude for most important feature and calculating\n",
    "#% explained by these features (more)\n",
    "ev = []\n",
    "magni = []\n",
    "more = []\n",
    "for j in Imp_feat:#['neg2-1_direct']:\n",
    "    if j.endswith('norm'):\n",
    "        Spectra = yeast_norm_nan\n",
    "    elif j.endswith('none'):\n",
    "        Spectra = yeast_none_nan\n",
    "    ratio = []\n",
    "    nsamples = []\n",
    "    n_groups = []\n",
    "    number = round(0.02*len(Spectra))\n",
    "    magni.append(Imp_feat[j][0][1]/(1/len(Spectra)))\n",
    "    a = 0\n",
    "    for i in range(number): \n",
    "        a = a + Imp_feat[j][i][1]*100 \n",
    "        ngroups = {}\n",
    "        line = Spectra.loc[Imp_feat[j][i][2],:].notnull()\n",
    "        nsamples.append(line.sum())\n",
    "        for n in range(len(line)):\n",
    "            if line[n] == True:\n",
    "                ngroups[Spectra.ms.labels[n]] = 1\n",
    "        n_groups.append(sum(list((ngroups.values()))))\n",
    "        ratio.append(nsamples[-1]/n_groups[-1])\n",
    "    more.append(a)\n",
    "    df = pd.DataFrame(columns = ['nsamples', 'n_groups', 'ratio'])\n",
    "    df['nsamples'] = nsamples\n",
    "    df['n_groups'] = n_groups\n",
    "    df['ratio']  = ratio\n",
    "    ev.append(df)\n",
    "#print(ev[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating averages of number of samples, groups and ratios and storing information in a DataFrame\n",
    "ratio_m = []\n",
    "samples_m = []\n",
    "groups_m = []\n",
    "for i in range(len(ev)):\n",
    "    samples_m.append(np.mean(ev[i].iloc[:,0]))\n",
    "    groups_m.append(np.mean(ev[i].iloc[:,1]))\n",
    "    ratio_m.append(np.mean(ev[i].iloc[:,2]))\n",
    "df = pd.DataFrame(columns = ['samples_m', 'groups_m', 'ratio_m'], index = [i  for i in Imp_feat])\n",
    "df['samples_m'] = samples_m\n",
    "df['groups_m'] = groups_m\n",
    "df['ratio_m'] = ratio_m\n",
    "\n",
    "#Inserting blank lines in the DataFrame for better presentation and separation\n",
    "line = pd.DataFrame({\"samples_m\": None, \"groups_m\": None, 'ratio_m':None}, index=[''])\n",
    "df = pd.concat([line, df.iloc[0:3],line, df.iloc[3:7],line, df.iloc[7:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(8, 6))\n",
    "mask = df.isnull()\n",
    "hm = sns.heatmap(df, annot=True, ax=ax, cmap = sns.cm.rocket_r, mask = mask)\n",
    "bottom, top = ax.get_ylim()\n",
    "ax.set_ylim(bottom + 0.5, top - 0.5)\n",
    "plt.text(1.4,0.6,'Norm')\n",
    "plt.text(1.4,4.6,'None')\n",
    "plt.text(1.34,9.6,'Binaries')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(20,8))\n",
    "data = [ev[i]['nsamples'] for i in range(len(ev))]\n",
    "#print(data)\n",
    "#sns.violinplot(data=data)\n",
    "sns.swarmplot(data=data, size = 5, palette = ['purple','blue','green','red','purple','blue','orange','green','red'])\n",
    "ax.set(xticklabels = [list(Imp_feat.keys())[i][0:13] for i in range(len(Imp_feat.keys()))])\n",
    "ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "plt.ylabel('Number of samples a feature is present', fontsize = 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Magnitude of most important feature:', magni)\n",
    "print('% of model explained by the 2% most important features', more)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Permutation Tests - Random Forests\n",
    "\n",
    "Permutation tests is based on shuffling the labels of the different samples, shuflling the groups where they belong with the intent to see if the classifier tested, whether it is random forests or pls-da found a significant class structure in the data. \n",
    "\n",
    "For that a random 3-fold cross-validation is performed on the original dataset (to serve as a comparation point) and 150 permutations of datasets with labels randomly shuffled around with the model being evaluated by how good the predictions the model does of the test data is. \n",
    "\n",
    "Histograms with the prediction accuracy of the different permutations were plotted and compared to the accuracy got with the original dataset.\n",
    "\n",
    "The empirical p-value is given by (the number of times the permutation accuracy was bigger than the random 3-fold cross-validation made with the original dataset + 1) / (number of permutations + 1) (source: Ojala2010 - error should be the opposite of the accuracy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV = {}\n",
    "PMs = {}\n",
    "pvalue = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permuta = ma.permutation_RF(Imp_norm, iter_num = 150, n_fold = 3)\n",
    "CV['Imp_norm'] = permuta[0]\n",
    "PMs['Imp_norm'] = permuta[1]\n",
    "pvalue['Imp_norm'] = permuta[2]\n",
    "\n",
    "permuta = ma.permutation_RF(P_norm, iter_num = 150, n_fold = 3)\n",
    "CV['P_norm'] = permuta[0]\n",
    "PMs['P_norm'] = permuta[1]\n",
    "pvalue['P_norm'] = permuta[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permuta = ma.permutation_RF(NGP_norm, iter_num = 150, n_fold = 3)\n",
    "CV['NGP_norm'] = permuta[0]\n",
    "PMs['NGP_norm'] = permuta[1]\n",
    "pvalue['NGP_norm'] = permuta[2]\n",
    "\n",
    "permuta = ma.permutation_RF(binary_norm, iter_num = 150, n_fold = 3)\n",
    "CV['bin_norm'] = permuta[0]\n",
    "PMs['bin_norm'] = permuta[1]\n",
    "pvalue['bin_norm'] = permuta[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permuta = ma.permutation_RF(Imp_none, iter_num = 150, n_fold = 3)\n",
    "CV['Imp_none'] = permuta[0]\n",
    "PMs['Imp_none'] = permuta[1]\n",
    "pvalue['Imp_none'] = permuta[2]\n",
    "\n",
    "permuta = ma.permutation_RF(P_none, iter_num = 150, n_fold = 3)\n",
    "CV['P_none'] = permuta[0]\n",
    "PMs['P_none'] = permuta[1]\n",
    "pvalue['P_none'] = permuta[2]\n",
    "\n",
    "permuta = ma.permutation_RF(NP_none, iter_num = 150, n_fold = 3)\n",
    "CV['NP_none'] = permuta[0]\n",
    "PMs['NP_none'] = permuta[1]\n",
    "pvalue['NP_none'] = permuta[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permuta = ma.permutation_RF(NGP_none, iter_num = 150, n_fold = 3)\n",
    "CV['NGP_none'] = permuta[0]\n",
    "PMs['NGP_none'] = permuta[1]\n",
    "pvalue['NGP_none'] = permuta[2]\n",
    "\n",
    "permuta = ma.permutation_RF(binary_none, iter_num = 150, n_fold = 3)\n",
    "CV['bin_none'] = permuta[0]\n",
    "PMs['bin_none'] = permuta[1]\n",
    "pvalue['bin_none'] = permuta[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(2, 2, figsize = (16,8))\n",
    "\n",
    "Names = ['Imp_norm', 'P_norm', 'NGP_norm', 'bin_norm']\n",
    "colors = ['purple', 'blue', 'green', 'red']\n",
    "quadrant = [axes[0][0], axes[0][1], axes[1][0], axes[1][1]]\n",
    "ylim = [0,50]\n",
    "n_labels = len(NGP_norm.ms.labels)\n",
    "\n",
    "#plt.suptitle('Permutation Tests - Random Forests')\n",
    "\n",
    "for q, name, color in zip(quadrant, Names, colors):\n",
    "    q.hist(PMs[name], n_labels, range=(0, 1.0001), label=name + ' Permutations',\n",
    "             edgecolor='black', color=color) #, alpha = 0.3)\n",
    "    \n",
    "    q.plot(2 * [CV[name]], ylim, '--g', linewidth=3, color=color, #alpha = 0.5,\n",
    "             label=name + ' (pvalue %.5f)' % pvalue[name])\n",
    "    q.set(xlabel='Prediction Accuracy', ylabel='N of occurrences')\n",
    "    q.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(2, 2, figsize = (16,8))\n",
    "\n",
    "Names = ['P_none', 'NP_none', 'NGP_none', 'bin_none']\n",
    "colors = ['purple', 'blue', 'green', 'red']\n",
    "quadrant = [axes[0][0], axes[0][1], axes[1][0], axes[1][1]]\n",
    "ylim = [0,50]\n",
    "n_labels = len(NGP_none.ms.labels)\n",
    "\n",
    "#plt.suptitle('Permutation Tests - Random Forests')\n",
    "\n",
    "for q, name, color in zip(quadrant, Names, colors):\n",
    "    q.hist(PMs[name], n_labels, range=(0, 1.0001), label=name + ' Permutations',\n",
    "             edgecolor='black', color=color) #, alpha = 0.3)\n",
    "    \n",
    "    q.plot(2 * [CV[name]], ylim, '--g', linewidth=3, color=color, #alpha = 0.5,\n",
    "             label=name + ' (pvalue %.5f)' % pvalue[name])\n",
    "    q.set(xlabel='Prediction Accuracy', ylabel='N of occurrences')\n",
    "    q.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1, 1, figsize = (16,8))\n",
    "\n",
    "Names = ['Imp_none']\n",
    "color = ['purple']\n",
    "ylim = [0,50]\n",
    "for i in range(len(Names)):\n",
    "    plt.hist(PMs[Names[i]], len(NGP_none.ms.labels), range = (0,1.0001), label = Names[i] + ' Permutations',\n",
    "             edgecolor='black', color = color[i])#, alpha = 0.3)\n",
    "    \n",
    "    plt.plot(2 * [CV[Names[i]]], ylim, '--g', linewidth=3, color = color[i], #alpha = 0.5,\n",
    "             label=Names[i] +\n",
    "             ' (pvalue %s)' % pvalue[Names[i]])\n",
    "    plt.xlabel('Prediction Accuracy')\n",
    "    plt.ylabel('N of occurrences')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Extracting a single decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(NGP_none.T, NGP_none.ms.labels, test_size=0.1)\n",
    "rf = skensemble.RandomForestClassifier(n_estimators = 200)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "from sklearn import tree\n",
    "fig = plt.figure(figsize=(20,12))\n",
    "clf = rf.estimators_[2].fit(X_train, y_train)\n",
    "tree.plot_tree(clf)\n",
    "print('Decision Tree')"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PLS-DA - Classification based on Partial Least Squares - Discriminant Analysis\n",
    "\n",
    "Creating the target vectors matrix where each different group is made into a column and 1 represents the sample belongs to that group (0 means it doesn't belong)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = pd.get_dummies(yeast_norm_nan.ms.labels)\n",
    "unique_labels = list(yeast_norm_nan.ms.unique_labels)\n",
    "matrix = matrix[unique_labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Search for the best number of components to use\n",
    "\n",
    "Strategy: Perform PLS-DA with different number of components and observe the score (both given directly by the method and the r2 score) and the mean-squared error (MSE) of the models built with 3-fold cross-validation (3 was chosen since it is the max for our dataset - 3 replicates in each group, having an added bonus of still maintaining a balanced dataset). Then plot the different results obtained and see at which point (number of components) the score and the MSE stops start approaching a \"stable value\".\n",
    "\n",
    "The maximum number of components tested was 30 (which was enough for the objective established above).\n",
    "\n",
    "Warnings are due to the type of scoring that will be changed in the next version of scikit learn.\n",
    "\n",
    "Function optim_PLS in multianalysis.py - performs PLS analysis and obtains the results stated above with number of components defined from 1 to max_comp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "#PLS applied in the MetScape Normalized Dataset.\n",
    "Imp_norm_PLS = ma.optim_PLS(Imp_norm, matrix, max_comp = 30)\n",
    "P_norm_PLS = ma.optim_PLS(P_norm, matrix, max_comp = 30)\n",
    "NGP_norm_PLS = ma.optim_PLS(NGP_norm, matrix, max_comp = 30)\n",
    "bin_norm_PLS = ma.optim_PLS(binary_norm, matrix, max_comp = 30)\n",
    "\n",
    "#PLS applied in the non-MetScape Normalized Dataset.\n",
    "Imp_none_PLS = ma.optim_PLS(Imp_none, matrix, max_comp = 30)\n",
    "P_none_PLS = ma.optim_PLS(P_none, matrix, max_comp = 30)\n",
    "NP_none_PLS = ma.optim_PLS(NP_none, matrix, max_comp = 30)\n",
    "NGP_none_PLS = ma.optim_PLS(NGP_none, matrix, max_comp = 30)\n",
    "bin_none_PLS = ma.optim_PLS(binary_none, matrix, max_comp = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(8,6))\n",
    "plt.plot(range(1,31),Imp_norm_PLS[0])\n",
    "plt.plot(range(1,31),P_norm_PLS[0])\n",
    "plt.plot(range(1,31),NGP_norm_PLS[0])\n",
    "plt.plot(range(1,31),bin_norm_PLS[0])\n",
    "plt.ylabel('PLS-DA Score', fontsize = 15)\n",
    "plt.xlabel('Number of Components', fontsize = 15)\n",
    "ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "ax.legend(('Imp', 'P', 'NGP', 'Binary'))\n",
    "print('Performance based on number of components - Normalized Mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(8,6))\n",
    "plt.plot(range(1,31),Imp_norm_PLS[2])\n",
    "plt.plot(range(1,31),P_norm_PLS[2])\n",
    "plt.plot(range(1,31),NGP_norm_PLS[2])\n",
    "plt.plot(range(1,31),bin_norm_PLS[2])\n",
    "plt.ylabel('Mean Squared Error of Predictions', fontsize = 15)\n",
    "plt.xlabel('Number of Components', fontsize = 15)\n",
    "ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "ax.legend(('Imp', 'P', 'NGP', 'Binary'))\n",
    "print('Performance based on number of components - Normalized Mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(8,6))\n",
    "plt.plot(range(1,31),P_none_PLS[0])\n",
    "plt.plot(range(1,31),NP_none_PLS[0])\n",
    "plt.plot(range(1,31),NGP_none_PLS[0])\n",
    "plt.plot(range(1,31),bin_none_PLS[0])\n",
    "plt.plot(range(1,31),Imp_none_PLS[0])\n",
    "plt.ylabel('PLS-DA Score', fontsize = 15)\n",
    "plt.xlabel('Number of Components', fontsize = 15)\n",
    "ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "ax.legend(('P', 'NP', 'NGP', 'Binary', 'Imp'))\n",
    "print('Performance based on number of components - Not-Normalized Mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(8,6))\n",
    "plt.plot(range(1,31),P_none_PLS[2])\n",
    "plt.plot(range(1,31),NP_none_PLS[2])\n",
    "plt.plot(range(1,31),NGP_none_PLS[2])\n",
    "plt.plot(range(1,31),bin_none_PLS[2])\n",
    "plt.plot(range(1,31),Imp_none_PLS[2])\n",
    "plt.ylabel('Mean Squared Error of Predictions', fontsize = 15)\n",
    "plt.xlabel('Number of Components', fontsize = 15)\n",
    "ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "ax.legend(('P', 'NP', 'NGP', 'Binary', 'Imp'))\n",
    "print('Performance based on number of components - Not-Normalized Mode')"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Application of PLS-DA\n",
    "\n",
    "The number of components seemed to be converged when it reached around 4/5 so 6 components were used from now on. Also MSE is the inverse of the score given by the PLS function of the module scikit-learn so from now on we will only collect the score knowing its meaning.\n",
    "\n",
    "We can now transform the PLS algorithm (PLS2 algorithm used) to give classification of samples instead of regression using a decision rule to interpret the y_pred result given for each test sample and decide what group it belongs to. In this case a simple rule of the group with the highest number (closer to 1) is decided to be the group to which said sample belongs to - naive MAX rule.\n",
    "\n",
    "Two metrics to evaluate the results were evaluated. First the score of the model as seen before but more importantly the second one is the accuracy of the model based on the decision rule stated above. All samples are tested once in 3 different groups as 3-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLS_accu = {}\n",
    "PLS_score = {}\n",
    "PLS_Feat = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "Imp_norm_PLS = ma.model_PLSDA(Imp_norm, matrix, n_comp = 6, iter_num = 100, feat_type = 'Coef')\n",
    "PLS_accu['Imp_norm'] = Imp_norm_PLS[0]\n",
    "PLS_score['Imp_norm'] = Imp_norm_PLS[1]\n",
    "PLS_Feat['Imp_norm'] = Imp_norm_PLS[3]\n",
    "\n",
    "P_norm_PLS = ma.model_PLSDA(P_norm, matrix, n_comp = 6, iter_num = 100, feat_type = 'Coef')\n",
    "PLS_accu['P_norm'] = P_norm_PLS[0]\n",
    "PLS_score['P_norm'] = P_norm_PLS[1]\n",
    "PLS_Feat['P_norm'] = P_norm_PLS[3]\n",
    "\n",
    "NGP_norm_PLS = ma.model_PLSDA(NGP_norm, matrix, n_comp = 6, iter_num = 100, feat_type = 'Coef')\n",
    "PLS_accu['NGP_norm'] = NGP_norm_PLS[0]\n",
    "PLS_score['NGP_norm'] = NGP_norm_PLS[1]\n",
    "PLS_Feat['NGP_norm'] = NGP_norm_PLS[3]\n",
    "\n",
    "bin_norm_PLS = ma.model_PLSDA(binary_norm, matrix, n_comp = 6, iter_num = 100, feat_type = 'Coef')\n",
    "PLS_accu['bin_norm'] = bin_norm_PLS[0]\n",
    "PLS_score['bin_norm'] = bin_norm_PLS[1]\n",
    "PLS_Feat['bin_norm'] = bin_norm_PLS[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "Imp_none_PLS = ma.model_PLSDA(Imp_none, matrix, n_comp = 6, iter_num = 100, feat_type = 'Coef')\n",
    "PLS_accu['Imp_none'] = Imp_none_PLS[0]\n",
    "PLS_score['Imp_none'] = Imp_none_PLS[1]\n",
    "PLS_Feat['Imp_none'] = Imp_none_PLS[3]\n",
    "\n",
    "P_none_PLS = ma.model_PLSDA(P_none, matrix, n_comp = 6, iter_num = 100, feat_type = 'Coef')\n",
    "PLS_accu['P_none'] = P_none_PLS[0]\n",
    "PLS_score['P_none'] = P_none_PLS[1]\n",
    "PLS_Feat['P_none'] = P_none_PLS[3]\n",
    "\n",
    "NP_none_PLS = ma.model_PLSDA(NP_none, matrix, n_comp = 6, iter_num = 100, feat_type = 'Coef')\n",
    "PLS_accu['NP_none'] = NP_none_PLS[0]\n",
    "PLS_score['NP_none'] = NP_none_PLS[1]\n",
    "PLS_Feat['NP_none'] = NP_none_PLS[3]\n",
    "\n",
    "NGP_none_PLS = ma.model_PLSDA(NGP_none, matrix, n_comp = 6, iter_num = 100, feat_type = 'Coef')\n",
    "PLS_accu['NGP_none'] = NGP_none_PLS[0]\n",
    "PLS_score['NGP_none'] = NGP_none_PLS[1]\n",
    "PLS_Feat['NGP_none'] = NGP_none_PLS[3]\n",
    "\n",
    "bin_none_PLS = ma.model_PLSDA(binary_none, matrix, n_comp = 6, iter_num = 100, feat_type = 'Coef')\n",
    "PLS_accu['bin_none'] = bin_none_PLS[0]\n",
    "PLS_score['bin_none'] = bin_none_PLS[1]\n",
    "PLS_Feat['bin_none'] = bin_none_PLS[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(13,6))\n",
    "colors = ['purple','blue','orange','green','red','purple','blue','green','red']\n",
    "sns.violinplot(data=pd.DataFrame.from_dict(PLS_accu), palette = colors, alpha = 0.5)\n",
    "plt.ylabel('Prediction Accuracy - PLS-DA', fontsize = 15)\n",
    "ax.tick_params(axis='both', which='major', labelsize= 15)\n",
    "print('Accuracy based on the dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12,6))\n",
    "plt.scatter(['Imp_norm']*len(PLS_score['Imp_norm']), PLS_score['Imp_norm'])\n",
    "plt.scatter(['P_norm']*len(PLS_score['P_norm']), PLS_score['P_norm'])\n",
    "plt.scatter(['NGP_norm']*len(PLS_score['NGP_norm']), PLS_score['NGP_norm'])\n",
    "plt.scatter(['bin_norm']*len(PLS_score['bin_norm']), PLS_score['bin_norm'])\n",
    "plt.scatter(['P_none']*len(PLS_score['P_none']), PLS_score['P_none'])\n",
    "plt.scatter(['NP_none']*len(PLS_score['NP_none']), PLS_score['NP_none'])\n",
    "plt.scatter(['NGP_none']*len(PLS_score['NGP_none']), PLS_score['NGP_none'])\n",
    "plt.scatter(['bin_none']*len(PLS_score['bin_none']), PLS_score['bin_none'])\n",
    "plt.ylabel('PLS-DA Model Score')\n",
    "print('Performance score based on the dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy = {}\n",
    "Accuracy['Imp_norm'] = np.mean(PLS_accu['Imp_norm'])\n",
    "Accuracy['P_norm'] = np.mean(PLS_accu['P_norm'])\n",
    "Accuracy['NGP_norm'] = np.mean(PLS_accu['NGP_norm'])\n",
    "Accuracy['bin_norm'] = np.mean(PLS_accu['bin_norm'])\n",
    "Accuracy['Imp_none'] = np.mean(PLS_accu['Imp_none'])\n",
    "Accuracy['P_none'] = np.mean(PLS_accu['P_none'])\n",
    "Accuracy['NP_none'] = np.mean(PLS_accu['NP_none'])\n",
    "Accuracy['NGP_none'] = np.mean(PLS_accu['NGP_none'])\n",
    "Accuracy['bin_none'] = np.mean(PLS_accu['bin_none'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy_H = pd.DataFrame(list(Accuracy.values()), index = Accuracy.keys()).T\n",
    "f, ax = plt.subplots(figsize=(10, 1))\n",
    "hm = sns.heatmap(Accuracy_H, annot=True, ax=ax, cmap = sns.cm.rocket_r, yticklabels = ['PLSDA_Accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Score = {}\n",
    "Score['Imp_norm'] = np.mean(PLS_score['Imp_norm'])\n",
    "Score['P_norm'] = np.mean(PLS_score['P_norm'])\n",
    "Score['NGP_norm'] = np.mean(PLS_score['NGP_norm'])\n",
    "Score['bin_norm'] = np.mean(PLS_score['bin_norm'])\n",
    "Score['Imp_none'] = np.mean(PLS_score['Imp_none'])\n",
    "Score['P_none'] = np.mean(PLS_score['P_none'])\n",
    "Score['NP_none'] = np.mean(PLS_score['NP_none'])\n",
    "Score['NGP_none'] = np.mean(PLS_score['NGP_none'])\n",
    "Score['bin_none'] = np.mean(PLS_score['bin_none'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Score_H = pd.DataFrame(list(Score.values()), index = Score.keys()).T\n",
    "f, ax = plt.subplots(figsize=(10, 1))\n",
    "hm = sns.heatmap(Score_H, annot=True, ax=ax, cmap = sns.cm.rocket_r, yticklabels = ['PLSDA_Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy_std = {}\n",
    "Accuracy_std['Imp_norm'] = np.std(PLS_accu['Imp_norm'])\n",
    "Accuracy_std['P_norm'] = np.std(PLS_accu['P_norm'])\n",
    "Accuracy_std['NGP_norm'] = np.std(PLS_accu['NGP_norm'])\n",
    "Accuracy_std['bin_norm'] = np.std(PLS_accu['bin_norm'])\n",
    "Accuracy_std['Imp_none'] = np.std(PLS_accu['Imp_none'])\n",
    "Accuracy_std['P_none'] = np.std(PLS_accu['P_none'])\n",
    "Accuracy_std['NP_none'] = np.std(PLS_accu['NP_none'])\n",
    "Accuracy_std['NGP_none'] = np.std(PLS_accu['NGP_none'])\n",
    "Accuracy_std['bin_none'] = np.std(PLS_accu['bin_none'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Score_std = {}\n",
    "Score_std['Imp_norm'] = np.std(PLS_score['Imp_norm'])\n",
    "Score_std['P_norm'] = np.std(PLS_score['P_norm'])\n",
    "Score_std['NGP_norm'] = np.std(PLS_score['NGP_norm'])\n",
    "Score_std['bin_norm'] = np.std(PLS_score['bin_norm'])\n",
    "Score_std['Imp_none'] = np.std(PLS_score['Imp_none'])\n",
    "Score_std['P_none'] = np.std(PLS_score['P_none'])\n",
    "Score_std['NP_none'] = np.std(PLS_score['NP_none'])\n",
    "Score_std['NGP_none'] = np.std(PLS_score['NGP_none'])\n",
    "Score_std['bin_none'] = np.std(PLS_score['bin_none'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy_H = pd.DataFrame(list(Accuracy.values()), index = Accuracy.keys(), columns  = ['Accuracy']).T\n",
    "Accuracy_H.loc['SD'] = list(Accuracy_std.values())\n",
    "Accuracy_H.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Score_H = pd.DataFrame(list(Score.values()), index = Score.keys(), columns  = ['Score']).T\n",
    "Score_H.loc['SD'] = list(Score_std.values())\n",
    "Score_H.T"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Characteristics of the most important features"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The characteristics of the most important features for each of the methods is done by the same process as applied in the random forests section of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the number of samples, groups, ratios for each important feature, magnitude for most important feature \n",
    "ev = []\n",
    "magni = []\n",
    "index = []\n",
    "\n",
    "for j in PLS_Feat:\n",
    "    if j.endswith('norm'):\n",
    "        Spectra = yeast_norm_nan\n",
    "    elif j.endswith('none'):\n",
    "        Spectra = yeast_none_nan\n",
    "    index.append(j)\n",
    "    ratio = []\n",
    "    nsamples = []\n",
    "    n_groups = []\n",
    "    number = round(0.02*len(Spectra))\n",
    "    total_m = 0\n",
    "    for i in range(len(PLS_Feat[j])):\n",
    "        total_m = total_m + PLS_Feat[j][i][1]\n",
    "    magni.append(PLS_Feat[j][0][1]/(total_m/len(Spectra)))\n",
    "    for i in range(number): \n",
    "        ngroups = {}\n",
    "        line = Spectra.data.loc[PLS_Feat[j][i][2],:].notnull()\n",
    "        nsamples.append(line.sum())\n",
    "        for n in range(len(line)):\n",
    "            if line[n] == True:\n",
    "                ngroups[Spectra.labels[n]] = 1\n",
    "        n_groups.append(sum(list((ngroups.values()))))\n",
    "        ratio.append(nsamples[-1]/n_groups[-1])\n",
    "    df = pd.DataFrame(columns = ['nsamples', 'n_groups', 'ratio'])\n",
    "    df['nsamples'] = nsamples\n",
    "    df['n_groups'] = n_groups\n",
    "    df['ratio']  = ratio\n",
    "    ev.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating averages of number of samples, groups and ratios and storing information in a DataFrame\n",
    "ratio_m = []\n",
    "samples_m = []\n",
    "groups_m = []\n",
    "for i in range(len(ev)):\n",
    "    samples_m.append(np.mean(ev[i].iloc[:,0]))\n",
    "    groups_m.append(np.mean(ev[i].iloc[:,1]))\n",
    "    ratio_m.append(np.mean(ev[i].iloc[:,2]))\n",
    "df = pd.DataFrame(columns = ['samples_m', 'groups_m', 'ratio_m'], index = index)\n",
    "df['samples_m'] = samples_m\n",
    "df['groups_m'] = groups_m\n",
    "df['ratio_m'] = ratio_m\n",
    "#print(df)\n",
    "#Inserting blank lines in the DataFrame for better presentation and separation\n",
    "line = pd.DataFrame({\"samples_m\": None, \"groups_m\": None, 'ratio_m':None}, index=[''])\n",
    "df = pd.concat([df.iloc[:4], line, df.iloc[4:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(6, 6))\n",
    "hm = sns.heatmap(df, annot=True, ax=ax, cmap = sns.cm.rocket_r)\n",
    "bottom, top = ax.get_ylim()\n",
    "ax.set_ylim(bottom + 0.5, top - 0.5)\n",
    "plt.text(1.5,-0.5,'PLS_RegCoef',horizontalalignment='center', verticalalignment='center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(20,8))\n",
    "data = [ev[i]['nsamples'] for i in range(len(ev))]\n",
    "\n",
    "sns.swarmplot(data=data, size = 7)\n",
    "ax.set(xticklabels = [list(PLS_Feat.keys())[i] for i in range(len(PLS_Feat.keys()))])\n",
    "ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "plt.ylabel('Number of samples a feature is present', fontsize = 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Magnitude of most important features for each case:')\n",
    "print(magni)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model with the full dataset and sample representation on the two most important Components/Latent Variables\n",
    "\n",
    "NGP data treatment for the non previously normalized dataset (None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_decomposition import PLSRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plsda = PLSRegression(n_components = 6)\n",
    "#Fitting the model and getting the X_scores\n",
    "plsda.fit(X=NGP_none.data.T,Y=matrix)\n",
    "LV_score = pd.DataFrame(plsda.x_scores_)\n",
    "\n",
    "#Preparing colours to separate different groups\n",
    "colours = cm.get_cmap('nipy_spectral', 5)\n",
    "col_lbl = colours(range(5))\n",
    "col_lbl = list(col_lbl)\n",
    "for i in range(len(col_lbl)):\n",
    "    a = 3*i\n",
    "    col_lbl.insert(a+1,col_lbl[a])\n",
    "    col_lbl.insert(a+2,col_lbl[a])\n",
    "\n",
    "    #Scatter plot\n",
    "ax = LV_score.iloc[:,0:2].plot(x=0, y=1, kind='scatter', s=50, alpha=0.7, c = col_lbl, figsize=(9,9))\n",
    "ax.set_xlabel(xlabel = 'Principal Component 1', size = 15)\n",
    "ax.set_ylabel(ylabel = 'Principal Component 2', size = 15)\n",
    "ax.tick_params(axis='both', which='major', labelsize = 15)\n",
    "#Labeling each point\n",
    "i = -1\n",
    "for n, x in enumerate(LV_score.values): \n",
    "    if n%3 == 0:\n",
    "        i = i + 1\n",
    "        label = Spectra.unique_labels()[i]\n",
    "                #label = LV_score.index.values[n]\n",
    "    ax.text(x[0],x[1],label, fontsize = 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Binary processed data for the non previously normalized dataset (None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plsda = PLSRegression(n_components = 6)\n",
    "#Fitting the model and getting the X_scores\n",
    "plsda.fit(X=binary_none.data.T,Y=matrix)\n",
    "LV_score = pd.DataFrame(plsda.x_scores_)\n",
    "\n",
    "#Preparing colours to separate different groups\n",
    "colours = cm.get_cmap('nipy_spectral', 5)\n",
    "col_lbl = colours(range(5))\n",
    "col_lbl = list(col_lbl)\n",
    "for i in range(len(col_lbl)):\n",
    "    a = 3*i\n",
    "    col_lbl.insert(a+1,col_lbl[a])\n",
    "    col_lbl.insert(a+2,col_lbl[a])\n",
    "\n",
    "#Scatter plot\n",
    "ax = LV_score.iloc[:,0:2].plot(x=0, y=1, kind='scatter', s=50, alpha=0.7, c = col_lbl, figsize=(9,9))\n",
    "ax.set_xlabel(xlabel = 'Principal Component 1', size = 15)\n",
    "ax.set_ylabel(ylabel = 'Principal Component 2', size = 15)\n",
    "ax.tick_params(axis='both', which='major', labelsize = 15)\n",
    "#Labeling each point\n",
    "i = -1\n",
    "for n, x in enumerate(LV_score.values): \n",
    "    if n%3 == 0:\n",
    "        i = i + 1\n",
    "        label = Spectra.unique_labels()[i]\n",
    "                #label = LV_score.index.values[n]\n",
    "    ax.text(x[0],x[1],label, fontsize = 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Permutation Tests - PLS-DA\n",
    "\n",
    "Same explanation as presented for Permutation Tests - Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_PLS = {}\n",
    "PMs_PLS = {}\n",
    "pvalue_PLS = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permuta = ma.permutation_PLSDA(Imp_norm, n_comp = 6, iter_num = 150)\n",
    "CV_PLS['Imp_norm'] = permuta[0]\n",
    "PMs_PLS['Imp_norm'] = permuta[1]\n",
    "pvalue_PLS['Imp_norm'] = permuta[2]\n",
    "\n",
    "permuta = ma.permutation_PLSDA(P_norm, n_comp = 6, iter_num = 150)\n",
    "CV_PLS['P_norm'] = permuta[0]\n",
    "PMs_PLS['P_norm'] = permuta[1]\n",
    "pvalue_PLS['P_norm'] = permuta[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permuta = ma.permutation_PLSDA(NGP_norm, n_comp = 6, iter_num = 150)\n",
    "CV_PLS['NGP_norm'] = permuta[0]\n",
    "PMs_PLS['NGP_norm'] = permuta[1]\n",
    "pvalue_PLS['NGP_norm'] = permuta[2]\n",
    "\n",
    "permuta = ma.permutation_PLSDA(binary_norm, n_comp = 6, iter_num = 150)\n",
    "CV_PLS['bin_norm'] = permuta[0]\n",
    "PMs_PLS['bin_norm'] = permuta[1]\n",
    "pvalue_PLS['bin_norm'] = permuta[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permuta = ma.permutation_PLSDA(Imp_none, n_comp = 6, iter_num = 150)\n",
    "CV_PLS['Imp_none'] = permuta[0]\n",
    "PMs_PLS['Imp_none'] = permuta[1]\n",
    "pvalue_PLS['Imp_none'] = permuta[2]\n",
    "\n",
    "permuta = ma.permutation_PLSDA(P_none, n_comp = 6, iter_num = 150)\n",
    "CV_PLS['P_none'] = permuta[0]\n",
    "PMs_PLS['P_none'] = permuta[1]\n",
    "pvalue_PLS['P_none'] = permuta[2]\n",
    "\n",
    "permuta = ma.permutation_PLSDA(NP_none, n_comp = 6, iter_num = 150)\n",
    "CV_PLS['NP_none'] = permuta[0]\n",
    "PMs_PLS['NP_none'] = permuta[1]\n",
    "pvalue_PLS['NP_none'] = permuta[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permuta = ma.permutation_PLSDA(NGP_none, n_comp = 6, iter_num = 150)\n",
    "CV_PLS['NGP_none'] = permuta[0]\n",
    "PMs_PLS['NGP_none'] = permuta[1]\n",
    "pvalue_PLS['NGP_none'] = permuta[2]\n",
    "\n",
    "permuta = ma.permutation_PLSDA(binary_none, n_comp = 6, iter_num = 150)\n",
    "CV_PLS['bin_none'] = permuta[0]\n",
    "PMs_PLS['bin_none'] = permuta[1]\n",
    "pvalue_PLS['bin_none'] = permuta[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(2, 2, figsize = (16,8))\n",
    "\n",
    "Names = ['Imp_norm', 'P_norm', 'NGP_norm', 'bin_norm']\n",
    "color = ['purple','blue', 'green', 'red']\n",
    "quadrant = [axes[0][0], axes[0][1], axes[1][0], axes[1][1]]\n",
    "ylim = [0,50]\n",
    "\n",
    "#plt.suptitle('Permutation Tests - Random Forests')\n",
    "\n",
    "for i in range(len(Names)):\n",
    "    quadrant[i].hist(PMs_PLS[Names[i]], len(NGP_none.labels), range = (0,1.0001), label = Names[i] + ' Permutations',\n",
    "             edgecolor='black', color = color[i])#, alpha = 0.3)\n",
    "    \n",
    "    quadrant[i].plot(2 * [CV_PLS[Names[i]]], ylim, '--g', linewidth=3, color = color[i], #alpha = 0.5,\n",
    "             label=Names[i] +\n",
    "             ' (pvalue %s)' % pvalue_PLS[Names[i]])\n",
    "    quadrant[i].set(xlabel = 'Prediction Accuracy',ylabel = 'N of occurrences')\n",
    "    quadrant[i].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(2, 2, figsize = (16,8))\n",
    "\n",
    "Names = ['P_none', 'NP_none', 'NGP_none', 'bin_none']\n",
    "color = ['blue', 'orange', 'green', 'red']\n",
    "quadrant = [axes[0][0], axes[0][1], axes[1][0], axes[1][1]]\n",
    "ylim = [0,50]\n",
    "for i in range(len(Names)):\n",
    "    quadrant[i].hist(PMs_PLS[Names[i]], len(NGP_none.labels), range = (0,1.0001), label = Names[i] + ' Permutations',\n",
    "             edgecolor='black', color = color[i])#, alpha = 0.3)\n",
    "    \n",
    "    quadrant[i].plot(2 * [CV_PLS[Names[i]]], ylim, '--g', linewidth=3, color = color[i], #alpha = 0.5,\n",
    "             label=Names[i] +\n",
    "             ' (pvalue %s)' % pvalue_PLS[Names[i]])\n",
    "    quadrant[i].set(xlabel = 'Prediction Accuracy',ylabel = 'N of occurrences')\n",
    "    quadrant[i].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1, 1, figsize = (16,8))\n",
    "\n",
    "Names = ['Imp_none']\n",
    "color = ['purple']\n",
    "ylim = [0,50]\n",
    "for i in range(len(Names)):\n",
    "    plt.hist(PMs_PLS[Names[i]], len(NGP_none.labels), range = (0,1.0001), label = Names[i] + ' Permutations',\n",
    "             edgecolor='black', color = color[i])#, alpha = 0.3)\n",
    "    \n",
    "    plt.plot(2 * [CV_PLS[Names[i]]], ylim, '--g', linewidth=3, color = color[i], #alpha = 0.5,\n",
    "             label=Names[i] +\n",
    "             ' (pvalue %s)' % pvalue_PLS[Names[i]])\n",
    "    plt.xlabel('Prediction Accuracy')\n",
    "    plt.ylabel('N of occurrences')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Feat_Selection_sim(VIP_s, Weight_s, RegCoef_s, percent = 0.02):\n",
    "    \"\"\"See the similarity of features chosen (% of intersection between them) with different methods.\"\"\"\n",
    "    number = round(percent*len(VIP_s))\n",
    "    VIP = []\n",
    "    Weights = []\n",
    "    RegCoef = []\n",
    "    for i in range(number):\n",
    "        VIP.append(VIP_s[:number][i][0])\n",
    "        Weights.append(Weight_s[:number][i][0])\n",
    "        RegCoef.append(RegCoef_s[:number][i][0])\n",
    "    Features = (VIP, Weights, RegCoef)\n",
    "    Table = pd.DataFrame(np.empty((3,3)), columns = ['VIP', 'Weights', 'RegCoef'], index = ['VIP', 'Weights', 'RegCoef'])\n",
    "    for i in range(len(Features)):\n",
    "        for j in range(len(Features)):\n",
    "            #list comprehension other way\n",
    "            Table.iloc[i,j] = len(set(Features[i]).intersection(Features[j]))/number\n",
    "    return Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}